{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8db863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 12:23:44.938237: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-11 12:23:45.046597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746980625.095808   96948 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746980625.107747   96948 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746980625.204509   96948 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746980625.204526   96948 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746980625.204527   96948 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746980625.204528   96948 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-11 12:23:45.214472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "\"\"\"\n",
    "POC: Load Analyze-format MRI (.hdr/.img) and HDF5 data in Python\n",
    "Requires: nibabel, h5py, numpy, matplotlib, pandas\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import nibabel as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6858b4c",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a28dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/Event.csv', './data/EyeTrack.csv', './data/Motion.csv', './data/ECoG.csv']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_dir = \"./data/\"\n",
    "data_l = glob(data_dir + '*.csv')\n",
    "print(data_l)\n",
    "\n",
    "event_df = pd.read_csv(data_l[0])\n",
    "eye_track_df = pd.read_csv(data_l[1])\n",
    "motion_df = pd.read_csv(data_l[2])\n",
    "\n",
    "# Monkey K2 (Kuma)\n",
    "# Electrodes [52 -> 64] and [121 -> 128] (inclusive) are in the medial wall of the macaque brain.\n",
    "ecog_df = pd.read_csv(data_l[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./imgs/K2.png\"\n",
    "raw_image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4271a",
   "metadata": {},
   "source": [
    "# Sulci Notes:\n",
    "Sulci from right to left\n",
    "1. Principal Sulcus (25 is at the principal sulcus)\n",
    "2. Arcuate Sulcus\n",
    "3. Central Sulcus\n",
    "4. Intraparietal Sulcus\n",
    "5. Lateral Sulcus or Sylvian Fissure (21 is at the conjunction of Superior Temporal Sulcus and Lateral Sulcus)\n",
    "6. Superior Temporal Sulcus\n",
    "7. Lunate Sulcus\n",
    "8. Unknown. Possibly Calcarine Sulcus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of manually mapping coordinates:\n",
    "import numpy as np\n",
    "\n",
    "# Example ECoG electrode positions on macaque brain (F99 space), in mm\n",
    "macaque_ecog_coords = np.array([\n",
    "    [10, -15, 5],\n",
    "    [12, -13, 6],\n",
    "    [14, -12, 8],\n",
    "    [16, -10, 9],\n",
    "])  # You can replace this with your actual data\n",
    "\n",
    "# Sample activity levels per electrode\n",
    "activity = np.array([0.2, 0.8, 0.5, 0.9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "\n",
    "# Load a macaque surface model (use appropriate path)\n",
    "lh_surface = nib.load('F99.L.inflated.gii')  # Left hemisphere inflated surface\n",
    "lh_coords = lh_surface.darrays[0].data\n",
    "lh_faces = lh_surface.darrays[1].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Build a fast nearest-neighbor mapping from electrode to surface\n",
    "tree = cKDTree(lh_coords)\n",
    "_, indices = tree.query(macaque_ecog_coords)\n",
    "\n",
    "# Create vertex color array\n",
    "vertex_colors = np.zeros(len(lh_coords))\n",
    "vertex_colors[indices] = activity\n",
    "\n",
    "# Visualize using pyvista\n",
    "plotter = pv.Plotter()\n",
    "mesh = pv.PolyData(lh_coords, lh_faces)\n",
    "mesh[\"Activity\"] = vertex_colors\n",
    "plotter.add_mesh(mesh, scalars=\"Activity\", cmap=\"hot\", show_edges=False)\n",
    "plotter.add_title(\"Macaque Brain ECoG Activity\")\n",
    "plotter.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake mapping: just mirror the coordinates to a human surface\n",
    "human_coords = macaque_ecog_coords * np.array([1.2, 1.3, 1.1]) + np.array([30, 40, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fsaverage surface (use FreeSurfer or download)\n",
    "fs_lh = nib.load('fsaverage/surf/lh.inflated.gii')\n",
    "fs_coords = fs_lh.darrays[0].data\n",
    "fs_faces = fs_lh.darrays[1].data\n",
    "\n",
    "# Map electrodes to closest surface points\n",
    "tree_h = cKDTree(fs_coords)\n",
    "_, fs_indices = tree_h.query(human_coords)\n",
    "\n",
    "# Create vertex color array\n",
    "vertex_colors_human = np.zeros(len(fs_coords))\n",
    "vertex_colors_human[fs_indices] = activity\n",
    "\n",
    "# Visualize\n",
    "plotter = pv.Plotter()\n",
    "mesh_h = pv.PolyData(fs_coords, fs_faces)\n",
    "mesh_h[\"Activity\"] = vertex_colors_human\n",
    "plotter.add_mesh(mesh_h, scalars=\"Activity\", cmap=\"coolwarm\", show_edges=False)\n",
    "plotter.add_title(\"Human Analogue of Macaque ECoG\")\n",
    "plotter.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
